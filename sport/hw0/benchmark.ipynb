{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # calculations with arrays\n",
    "import pandas as pd # user-friendly DataFrames for data representation\n",
    "import sklearn # machine learning algorithms\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt # import plot functions\n",
    "# necessary to plot in jupyter notebook:\n",
    "%matplotlib inline\n",
    "import seaborn as sns # make plots beautiful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from competition's page\n",
    "\n",
    "https://inclass.kaggle.com/c/data-mining-in-action-2016-competitions-01/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2998</td>\n",
       "      <td>19</td>\n",
       "      <td>317</td>\n",
       "      <td>131</td>\n",
       "      <td>336</td>\n",
       "      <td>278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  day  team1  team2  score1  score2 target\n",
       "0  2998   19    317    131     336     278   True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2\n",
       "0   0  3021    363    161"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0     0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target variable is \"target\" and this means we will be predicting it\n",
    "sample_submission[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the unique values in data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year [2998 2999 3000 3001 3002]\n",
      "day [19 28 30 31 33]\n",
      "team1 [317  61 110 352 229]\n",
      "team2 [131  29 141 146  91]\n",
      "score1 [336 301 359 309 332]\n",
      "score2 [278 259 267 410 220]\n",
      "target [True False]\n"
     ]
    }
   ],
   "source": [
    "for c in train.columns:\n",
    "    print c, train[c].unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets split data randomly to train and validatation. We will train our algorithms on selected train set and validate them on validation set. Easy as it can be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101609, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train size\n",
    "train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is quite big, so for example purposes we'll sample only part of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "for itr, ite in ShuffleSplit(len(train), n_iter=1, train_size=0.4, test_size=0.1, random_state=0):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "information about all functions can be found on the internet, for example\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or you can open it in you Jupyter notebook executing function in this manner\n",
    "?ShuffleSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40643, 10161)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itr), len(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22710, 41665, 91975, 57348, 39931]),\n",
       " array([ 37078, 101474,  29858,  61674,   1049]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itr[:5], ite[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have validation set \"ite\" to check the quality of our solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0     0.5\n",
       "1   1     0.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to change 'target' column in \"sample_submission\" to our predictions.\n",
    "\n",
    "For now we will select only features that are present in both train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"year\" is present in test and train\n",
      "\"day\" is NOT present in test\n",
      "\"team1\" is present in test and train\n",
      "\"team2\" is present in test and train\n",
      "\"score1\" is NOT present in test\n",
      "\"score2\" is NOT present in test\n",
      "\"target\" is NOT present in test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['year', 'team1', 'team2']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for c in train.columns:\n",
    "    if c in test.columns and c!='target':\n",
    "        features += [c]\n",
    "        print '\"{}\" is present in test and train'.format(c)\n",
    "    else:\n",
    "        print '\"{}\" is NOT present in test'.format(c)\n",
    "        \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we split train on \"train\" and \"validation\" parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain = train.loc[itr, features]    \n",
    "ytrain = train.loc[itr, 'target']\n",
    "\n",
    "xval = train.loc[ite, features]\n",
    "yval = train.loc[ite, 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "lets make baseline first by predicting the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50096940231672393"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5009694,  0.5009694,  0.5009694, ...,  0.5009694,  0.5009694,\n",
       "        0.5009694])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_prediction = yval * 0 + train.target.mean()\n",
    "constant_prediction = constant_prediction.values\n",
    "constant_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931565015839517"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, constant_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.target = train['target'].mean() # notice here that we can refer to a column 'target' in two ways\n",
    "submission.to_csv('constant_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this should score like \"Baseline - Constant\" on Leaderboard!\n",
    "You can submit this by going to \n",
    "\n",
    "https://inclass.kaggle.com/c/data-mining-in-action-2016-competitions-01/submissions/attach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008,\n",
       "       3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019])"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(train.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3021, 3020])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.unique(test.year) # нужно предсказать результаты последующих матчей по предыдущим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year', 'team1', 'team2']"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr = train[train.year < 3018]\n",
    "val = train[train.year >= 3018]\n",
    "\n",
    "xtrain = tr.loc[:, features]    \n",
    "ytrain = tr.loc[:, 'target']\n",
    "\n",
    "xval = val.loc[:, features]\n",
    "yval = val.loc[:, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features adding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = train.loc[itr]\n",
    "val_set = train.loc[ite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq_counter = (train.groupby(\"team2\").count().target + train.groupby(\"team1\").count().target).to_dict()\n",
    "# сколько раз играла каждая команда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_names = sorted(pd.unique(train[\"team1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "av_scores={}\n",
    "for team_name in team_names:\n",
    "    av_scores[team_name] = (train[train.team1 == team_name].score1.mean() + train[train.team2 == team_name].score2.mean())/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.85 s, sys: 21.1 ms, total: 1.88 s\n",
      "Wall time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = {}\n",
    "for team_name in team_names:\n",
    "    prob_t1 = float(train[train[\"team1\"]==team_name].target.sum())/train[train[\"team1\"]==team_name].target.shape[0]\n",
    "    prob_t2 = 1 - float(train[train[\"team2\"]==team_name].target.sum())/train[train[\"team2\"]==team_name].target.shape[0]\n",
    "\n",
    "    all_prob_to_win = 0.5*(prob_t1 + prob_t2)    ## probability that team wins\n",
    "    d[team_name] = all_prob_to_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train[\"prob_t1_win\"] = train[\"team1\"].apply(lambda x: d.get(x, 0.5))\n",
    "train[\"prob_t2_win\"] = train[\"team2\"].apply(lambda x: d.get(x, 0.5))\n",
    "train[\"freq_cnt\"] = train[\"team2\"].apply(lambda x: freq_counter.get(x, 0))\n",
    "train[\"av_score\"] = train[\"team2\"].apply(lambda x: av_scores.get(x, 0))\n",
    "\n",
    "tr = train[train.year < 3018]\n",
    "val = train[train.year >= 3018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/d.parpulov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/d.parpulov/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "tr.drop([\"day\", \"year\", \"score1\", \"score2\", \"team1\", \"team2\"], axis=1, inplace=True)\n",
    "val.drop([\"day\", \"year\", \"score1\", \"score2\", \"team1\", \"team2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat = list(tr.columns)\n",
    "feat.remove('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prob_t1_win', 'prob_t2_win', 'freq_cnt', 'av_score']"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = train.loc[itr, feat]    \n",
    "ytrain = train.loc[itr, 'target']\n",
    "\n",
    "xval = train.loc[ite, feat]\n",
    "yval = train.loc[ite, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain = tr.loc[:, feat]    \n",
    "ytrain = tr.loc[:, 'target']\n",
    "\n",
    "xval = val.loc[:, feat]\n",
    "yval = val.loc[:, 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['max_depth'] = 2\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.15\n",
    "#param['n_estimators'] = 10\n",
    "param['subsample'] = 0.6\n",
    "param['colsample_bytree'] = 0.6\n",
    "\n",
    "numround = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68698\teval-logloss:0.687772\n",
      "[10]\ttrain-logloss:0.643444\teval-logloss:0.645914\n",
      "[20]\ttrain-logloss:0.629259\teval-logloss:0.633108\n",
      "[30]\ttrain-logloss:0.622403\teval-logloss:0.62701\n",
      "[40]\ttrain-logloss:0.618663\teval-logloss:0.623989\n",
      "[50]\ttrain-logloss:0.617567\teval-logloss:0.623701\n",
      "[60]\ttrain-logloss:0.617051\teval-logloss:0.623422\n",
      "[70]\ttrain-logloss:0.616074\teval-logloss:0.62296\n",
      "[80]\ttrain-logloss:0.615465\teval-logloss:0.622746\n",
      "[90]\ttrain-logloss:0.614939\teval-logloss:0.622579\n",
      "[100]\ttrain-logloss:0.614613\teval-logloss:0.622833\n",
      "[110]\ttrain-logloss:0.614308\teval-logloss:0.622814\n",
      "[120]\ttrain-logloss:0.613925\teval-logloss:0.622806\n",
      "[130]\ttrain-logloss:0.61364\teval-logloss:0.623003\n",
      "[140]\ttrain-logloss:0.613294\teval-logloss:0.622542\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgb.DMatrix(data = xtrain, label = ytrain)\n",
    "Xdatatest = xgb.DMatrix(data = xval, label = yval)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgb.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)\n",
    "# ypredxgb_tr = bst.predict(Xdatatrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = xgb.DMatrix(data = train[feat], label = train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.678579\n",
      "[10]\ttrain-logloss:0.624711\n",
      "[20]\ttrain-logloss:0.615956\n",
      "[30]\ttrain-logloss:0.613713\n",
      "[40]\ttrain-logloss:0.612369\n",
      "[50]\ttrain-logloss:0.611221\n",
      "[60]\ttrain-logloss:0.610241\n",
      "[70]\ttrain-logloss:0.609353\n",
      "[80]\ttrain-logloss:0.608193\n",
      "[90]\ttrain-logloss:0.607353\n",
      "[100]\ttrain-logloss:0.606773\n",
      "[110]\ttrain-logloss:0.605908\n",
      "[120]\ttrain-logloss:0.605437\n",
      "[130]\ttrain-logloss:0.60468\n",
      "[140]\ttrain-logloss:0.604049\n",
      "[150]\ttrain-logloss:0.603518\n",
      "[160]\ttrain-logloss:0.60278\n",
      "[170]\ttrain-logloss:0.602382\n",
      "[180]\ttrain-logloss:0.601766\n",
      "[190]\ttrain-logloss:0.601343\n",
      "[200]\ttrain-logloss:0.600959\n",
      "[210]\ttrain-logloss:0.60042\n",
      "[220]\ttrain-logloss:0.599958\n",
      "[230]\ttrain-logloss:0.599566\n",
      "[240]\ttrain-logloss:0.599087\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(plst, tr, numround, evals = [(tr, 'train')], verbose_eval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"prob_t1_win\"] = test[\"team1\"].apply(lambda x: d.get(x, 0.5))\n",
    "test[\"prob_t2_win\"] = test[\"team2\"].apply(lambda x: d.get(x, 0.5))\n",
    "test[\"freq_cnt\"] = test[\"team2\"].apply(lambda x: freq_counter.get(x, 0))\n",
    "test[\"av_score\"] = test[\"team2\"].apply(lambda x: av_scores.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.drop([\"year\", \"team1\", \"team2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = sample_submission.copy()\n",
    "ss.target = bst.predict(xgb.DMatrix(test[feat]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss.to_csv('tuned_xgboost2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Смешать несколько разных моделей: бустинг, линейную модель, случайный лес. Например взять взвешенную сумму предсказаний: coeff1 * ypred1 + (1 - coeff1) * ypred2.\n",
    "\n",
    "2) Сделать несложный трюк с данными перед тем как отдавать их в бустинг) Требует понимания структуры данных.\n",
    "\n",
    "3) Добавить новые фичи :) Опять же, нужно использовать понимание того, с какими данными мы имеем дело.\n",
    "\n",
    "Любой из этих идей может быть достаточно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prob solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pd.unique(train[\"team1\"])) == sorted(pd.unique(train[\"team2\"])) # the same commands!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_names = sorted(pd.unique(train[\"team1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967152686762779"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_name = 317\n",
    "prob_t1 = float(train[train[\"team1\"]==team_name].target.sum())/train[train[\"team1\"]==team_name].target.shape[0]\n",
    "prob_t2 = 1 - float(train[train[\"team2\"]==team_name].target.sum())/train[train[\"team2\"]==team_name].target.shape[0]\n",
    "\n",
    "all_prob_to_win = 0.5*(prob_t1 + prob_t2)    ## probability that team wins\n",
    "all_prob_to_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 22.1 ms, total: 1.97 s\n",
      "Wall time: 1.99 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = {}\n",
    "for team_name in team_names:\n",
    "    prob_t1 = float(train[train[\"team1\"]==team_name].target.sum())/train[train[\"team1\"]==team_name].target.shape[0]\n",
    "    prob_t2 = 1 - float(train[train[\"team2\"]==team_name].target.sum())/train[train[\"team2\"]==team_name].target.shape[0]\n",
    "\n",
    "    all_prob_to_win = 0.5*(prob_t1 + prob_t2)    ## probability that team wins\n",
    "    d[team_name] = all_prob_to_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7885674931129476"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_set[\"prob_t1_win\"] = val_set[\"team1\"].apply(lambda x: d.get(x, 0.5))\n",
    "val_set[\"prob_t2_win\"] = val_set[\"team2\"].apply(lambda x: d.get(x, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_set[\"prob_t2_lost\"] = 1 - val_set[\"prob_t2_win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "      <th>prob_t1_win</th>\n",
       "      <th>prob_t2_win</th>\n",
       "      <th>prob_t2_lost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37078</th>\n",
       "      <td>3006</td>\n",
       "      <td>214</td>\n",
       "      <td>305</td>\n",
       "      <td>196</td>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "      <td>0.472638</td>\n",
       "      <td>0.362673</td>\n",
       "      <td>0.637327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101474</th>\n",
       "      <td>3019</td>\n",
       "      <td>226</td>\n",
       "      <td>361</td>\n",
       "      <td>207</td>\n",
       "      <td>178</td>\n",
       "      <td>228</td>\n",
       "      <td>False</td>\n",
       "      <td>0.509714</td>\n",
       "      <td>0.673565</td>\n",
       "      <td>0.326435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29858</th>\n",
       "      <td>3005</td>\n",
       "      <td>95</td>\n",
       "      <td>178</td>\n",
       "      <td>204</td>\n",
       "      <td>212</td>\n",
       "      <td>197</td>\n",
       "      <td>True</td>\n",
       "      <td>0.578424</td>\n",
       "      <td>0.540334</td>\n",
       "      <td>0.459666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61674</th>\n",
       "      <td>3012</td>\n",
       "      <td>90</td>\n",
       "      <td>290</td>\n",
       "      <td>243</td>\n",
       "      <td>224</td>\n",
       "      <td>131</td>\n",
       "      <td>True</td>\n",
       "      <td>0.666226</td>\n",
       "      <td>0.628230</td>\n",
       "      <td>0.371770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>2998</td>\n",
       "      <td>93</td>\n",
       "      <td>354</td>\n",
       "      <td>186</td>\n",
       "      <td>270</td>\n",
       "      <td>259</td>\n",
       "      <td>True</td>\n",
       "      <td>0.486889</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.533419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  day  team1  team2  score1  score2 target  prob_t1_win  \\\n",
       "37078   3006  214    305    196     263     247   True     0.472638   \n",
       "101474  3019  226    361    207     178     228  False     0.509714   \n",
       "29858   3005   95    178    204     212     197   True     0.578424   \n",
       "61674   3012   90    290    243     224     131   True     0.666226   \n",
       "1049    2998   93    354    186     270     259   True     0.486889   \n",
       "\n",
       "        prob_t2_win  prob_t2_lost  \n",
       "37078      0.362673      0.637327  \n",
       "101474     0.673565      0.326435  \n",
       "29858      0.540334      0.459666  \n",
       "61674      0.628230      0.371770  \n",
       "1049       0.466581      0.533419  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_set[\"pred\"] = (val_set[\"prob_t1_win\"] + val_set[\"prob_t2_lost\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65163204966445343"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(list(val_set[\"target\"]), list(val_set[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test2.csv')\n",
    "for_subm = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_subm[\"prob_t1_win\"] = for_subm[\"team1\"].apply(lambda x: d.get(x, 0.5))\n",
    "for_subm[\"prob_t2_win\"] = for_subm[\"team2\"].apply(lambda x: d.get(x, 0.5))\n",
    "for_subm[\"prob_t2_lost\"] = 1 - for_subm[\"prob_t2_win\"]\n",
    "\n",
    "for_subm[\"target\"] = (for_subm[\"prob_t1_win\"] + for_subm[\"prob_t2_lost\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>prob_t1_win</th>\n",
       "      <th>prob_t2_win</th>\n",
       "      <th>prob_t2_lost</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "      <td>0.429540</td>\n",
       "      <td>0.543362</td>\n",
       "      <td>0.456638</td>\n",
       "      <td>0.443089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3021</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "      <td>0.578631</td>\n",
       "      <td>0.387953</td>\n",
       "      <td>0.612047</td>\n",
       "      <td>0.595339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3020</td>\n",
       "      <td>232</td>\n",
       "      <td>52</td>\n",
       "      <td>0.546586</td>\n",
       "      <td>0.211810</td>\n",
       "      <td>0.788190</td>\n",
       "      <td>0.667388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3020</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>0.429677</td>\n",
       "      <td>0.487874</td>\n",
       "      <td>0.512126</td>\n",
       "      <td>0.470902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3021</td>\n",
       "      <td>305</td>\n",
       "      <td>39</td>\n",
       "      <td>0.472638</td>\n",
       "      <td>0.688156</td>\n",
       "      <td>0.311844</td>\n",
       "      <td>0.392241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2  prob_t1_win  prob_t2_win  prob_t2_lost    target\n",
       "0   0  3021    363    161     0.429540     0.543362      0.456638  0.443089\n",
       "1   1  3021    286      2     0.578631     0.387953      0.612047  0.595339\n",
       "2   2  3020    232     52     0.546586     0.211810      0.788190  0.667388\n",
       "3   3  3020     84     11     0.429677     0.487874      0.512126  0.470902\n",
       "4   4  3021    305     39     0.472638     0.688156      0.311844  0.392241"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_subm.drop([\"prob_t1_win\", \"prob_t2_win\", \"prob_t2_lost\", \"year\", \"team1\", \"team2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0       0\n",
       "1   1       1\n",
       "2   2       1\n",
       "3   3       0\n",
       "4   4       0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_subm.to_csv(\"prob_solution3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "Finally, lets try machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = linear_model.LogisticRegression()\n",
    "alg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69278081748011511"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, not so far from the constant solution... Let's try to understand why.\n",
    "\n",
    "What's a linear model such as LogisticRegression is trying to do is multiply each variable on some coefficient and add add it up, in our case:\n",
    "\n",
    "y_predicted = column1 \\* coef1 + column2 \\* coef2 + column3 \\* coef3 + bias\n",
    "\n",
    "We can print coefficients and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  1.78001477e-07,   3.28971478e-04,  -2.98418706e-04]]),\n",
       " array([  3.70539525e-09]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.coef_, alg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But clearly, \"team1\" and \"team2\" are _categorical_ columns, just like names of the teams. \n",
    "\n",
    "So we need to turn \"team\" columns to something linear algorithm can work with. For example first few rows from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    317\n",
       "1     61\n",
       "2    110\n",
       "Name: team1, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:2, 'team1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>61</th>\n",
       "      <th>110</th>\n",
       "      <th>317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   61   110  317\n",
       "0  0.0  0.0  1.0\n",
       "1  1.0  0.0  0.0\n",
       "2  0.0  1.0  0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train.loc[:2, 'team1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each team name now has it's own column. Read about \"pd.get_dummies\" here:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But let's come back to more interesting stuff for now\n",
    "### We are competition's solvers, remember? Lets dive into the space of more complicated models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = ensemble.RandomForestClassifier(15, n_jobs=4)\n",
    "alg.fit(xtrain, ytrain)\n",
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1153333082796977"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, this doesn't work very well. Now, like competition pro, let's make our models bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = ensemble.RandomForestClassifier(150, n_jobs=4)\n",
    "alg.fit(xtrain, ytrain)\n",
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7388226194069718"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost there! But for now let's skip this model too and go to _real_ competitions stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['max_depth'] = 8\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.2\n",
    "\n",
    "param['subsample'] = 0.7\n",
    "param['colsample_bytree'] = 0.7\n",
    "\n",
    "numround = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('colsample_bytree', 0.7),\n",
       " ('eval_metric', 'logloss'),\n",
       " ('subsample', 0.7),\n",
       " ('eta', 0.2),\n",
       " ('objective', 'binary:logistic'),\n",
       " ('max_depth', 8),\n",
       " ('booster', 'gbtree')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost parameters\n",
    "\n",
    "https://github.com/dmlc/xgboost/blob/master/doc/parameter.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e1e8f0023c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mXdatatrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mXdatatest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXdatatrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mXdatatest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgb.DMatrix(data = xtrain, label = ytrain)\n",
    "Xdatatest = xgb.DMatrix(data = xval, label = yval)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgb.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)\n",
    "# ypredxgb_tr = bst.predict(Xdatatrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Finally our model better than constant predictions! Congratulations! Don't hesitate, submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr = xgb.DMatrix(data = train[features], label = train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.689124\n",
      "[10]\ttrain-logloss:0.658489\n",
      "[20]\ttrain-logloss:0.64207\n",
      "[30]\ttrain-logloss:0.628206\n",
      "[40]\ttrain-logloss:0.615129\n",
      "[50]\ttrain-logloss:0.605808\n",
      "[60]\ttrain-logloss:0.597754\n",
      "[70]\ttrain-logloss:0.591092\n",
      "[80]\ttrain-logloss:0.583741\n",
      "[90]\ttrain-logloss:0.577176\n",
      "[100]\ttrain-logloss:0.572124\n",
      "[110]\ttrain-logloss:0.566043\n",
      "[120]\ttrain-logloss:0.560684\n",
      "[130]\ttrain-logloss:0.555131\n",
      "[140]\ttrain-logloss:0.550893\n",
      "[150]\ttrain-logloss:0.547827\n",
      "[160]\ttrain-logloss:0.543338\n",
      "[170]\ttrain-logloss:0.540397\n",
      "[180]\ttrain-logloss:0.537018\n",
      "[190]\ttrain-logloss:0.533727\n"
     ]
    }
   ],
   "source": [
    "bst = xgb.train(plst, tr, numround, evals = [(tr, 'train')], verbose_eval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = sample_submission.copy()\n",
    "\n",
    "ss.target = bst.predict(xgb.DMatrix(test[features]))\n",
    "ss.to_csv('tuned_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost with hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "import sys\n",
    "# The path to XGBoost wrappers goes here\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(params):\n",
    "    print \"Training with params : \"\n",
    "    print params\n",
    "    num_round = int(params['n_estimators'])\n",
    "    del params['n_estimators']\n",
    "    dtrain = xgb.DMatrix(data = xtrain, label = ytrain)\n",
    "    dvalid = xgb.DMatrix(data = xval, label = yval)\n",
    "    watchlist = [(dvalid, 'eval'), (dtrain, 'train')]\n",
    "    model = xgb.train(params, dtrain, num_round, evals=watchlist, verbose_eval = 10)\n",
    "    predictions = model.predict(dvalid)\n",
    "    score = log_loss(yval, predictions)\n",
    "    print \"\\tScore {0}\\n\\n\".format(score)\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : 200, #hp.choice('n_estimators', np.arange(100, 200, 50, dtype=int)),\n",
    "             #'eta' : 0.1, #hp.choice('eta', np.arange(0.1, 0.2, 0.1, dtype=float)),\n",
    "             'max_depth' : hp.choice('max_depth', np.arange(8, 12)),\n",
    "             #'subsample' : 0.7,#hp.choice('subsample', np.arange(0.7, 0.9, 0.1, dtype=float)),\n",
    "             #'colsample_bytree' : 0.7,#hp.choice('colsample_bytree', np.arange(0.7, 0.9, 0.1, dtype=float)),\n",
    "             #'booster': 'gbtree',\n",
    "             'eval_metric': 'logloss',\n",
    "             'objective': 'binary:logistic',\n",
    "             'silent' : 1\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "\n",
    "    print best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 10, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687281\ttrain-logloss:0.678226\n",
      "[10]\teval-logloss:0.662086\ttrain-logloss:0.61144\n",
      "[20]\teval-logloss:0.6538\ttrain-logloss:0.576151\n",
      "[30]\teval-logloss:0.6497\ttrain-logloss:0.550356\n",
      "[40]\teval-logloss:0.643803\ttrain-logloss:0.519673\n",
      "[50]\teval-logloss:0.644238\ttrain-logloss:0.505495\n",
      "[60]\teval-logloss:0.643028\ttrain-logloss:0.483072\n",
      "[70]\teval-logloss:0.64279\ttrain-logloss:0.463482\n",
      "[80]\teval-logloss:0.64387\ttrain-logloss:0.444722\n",
      "[90]\teval-logloss:0.645035\ttrain-logloss:0.433404\n",
      "[100]\teval-logloss:0.646799\ttrain-logloss:0.42103\n",
      "[110]\teval-logloss:0.648315\ttrain-logloss:0.409799\n",
      "[120]\teval-logloss:0.65037\ttrain-logloss:0.400508\n",
      "[130]\teval-logloss:0.651744\ttrain-logloss:0.389124\n",
      "[140]\teval-logloss:0.653998\ttrain-logloss:0.380241\n",
      "[150]\teval-logloss:0.655873\ttrain-logloss:0.370247\n",
      "[160]\teval-logloss:0.658325\ttrain-logloss:0.36262\n",
      "[170]\teval-logloss:0.660668\ttrain-logloss:0.354537\n",
      "[180]\teval-logloss:0.662141\ttrain-logloss:0.347834\n",
      "[190]\teval-logloss:0.663946\ttrain-logloss:0.340881\n",
      "\tScore 0.665693369627\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 10, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687281\ttrain-logloss:0.678226\n",
      "[10]\teval-logloss:0.662086\ttrain-logloss:0.61144\n",
      "[20]\teval-logloss:0.6538\ttrain-logloss:0.576151\n",
      "[30]\teval-logloss:0.6497\ttrain-logloss:0.550356\n",
      "[40]\teval-logloss:0.643803\ttrain-logloss:0.519673\n",
      "[50]\teval-logloss:0.644238\ttrain-logloss:0.505495\n",
      "[60]\teval-logloss:0.643028\ttrain-logloss:0.483072\n",
      "[70]\teval-logloss:0.64279\ttrain-logloss:0.463482\n",
      "[80]\teval-logloss:0.64387\ttrain-logloss:0.444722\n",
      "[90]\teval-logloss:0.645035\ttrain-logloss:0.433404\n",
      "[100]\teval-logloss:0.646799\ttrain-logloss:0.42103\n",
      "[110]\teval-logloss:0.648315\ttrain-logloss:0.409799\n",
      "[120]\teval-logloss:0.65037\ttrain-logloss:0.400508\n",
      "[130]\teval-logloss:0.651744\ttrain-logloss:0.389124\n",
      "[140]\teval-logloss:0.653998\ttrain-logloss:0.380241\n",
      "[150]\teval-logloss:0.655873\ttrain-logloss:0.370247\n",
      "[160]\teval-logloss:0.658325\ttrain-logloss:0.36262\n",
      "[170]\teval-logloss:0.660668\ttrain-logloss:0.354537\n",
      "[180]\teval-logloss:0.662141\ttrain-logloss:0.347834\n",
      "[190]\teval-logloss:0.663946\ttrain-logloss:0.340881\n",
      "\tScore 0.665693369627\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 9, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687678\ttrain-logloss:0.681541\n",
      "[10]\teval-logloss:0.663159\ttrain-logloss:0.626614\n",
      "[20]\teval-logloss:0.650574\ttrain-logloss:0.589226\n",
      "[30]\teval-logloss:0.644027\ttrain-logloss:0.564169\n",
      "[40]\teval-logloss:0.640947\ttrain-logloss:0.542582\n",
      "[50]\teval-logloss:0.638108\ttrain-logloss:0.522781\n",
      "[60]\teval-logloss:0.636427\ttrain-logloss:0.506962\n",
      "[70]\teval-logloss:0.636164\ttrain-logloss:0.493793\n",
      "[80]\teval-logloss:0.63623\ttrain-logloss:0.479283\n",
      "[90]\teval-logloss:0.636197\ttrain-logloss:0.466736\n",
      "[100]\teval-logloss:0.637647\ttrain-logloss:0.454999\n",
      "[110]\teval-logloss:0.637489\ttrain-logloss:0.44585\n",
      "[120]\teval-logloss:0.637884\ttrain-logloss:0.437385\n",
      "[130]\teval-logloss:0.6379\ttrain-logloss:0.426372\n",
      "[140]\teval-logloss:0.639092\ttrain-logloss:0.417036\n",
      "[150]\teval-logloss:0.640307\ttrain-logloss:0.407873\n",
      "[160]\teval-logloss:0.642882\ttrain-logloss:0.399802\n",
      "[170]\teval-logloss:0.643988\ttrain-logloss:0.39344\n",
      "[180]\teval-logloss:0.645051\ttrain-logloss:0.388235\n",
      "[190]\teval-logloss:0.647098\ttrain-logloss:0.381713\n",
      "\tScore 0.648086884226\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 10, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687281\ttrain-logloss:0.678226\n",
      "[10]\teval-logloss:0.662086\ttrain-logloss:0.61144\n",
      "[20]\teval-logloss:0.6538\ttrain-logloss:0.576151\n",
      "[30]\teval-logloss:0.6497\ttrain-logloss:0.550356\n",
      "[40]\teval-logloss:0.643803\ttrain-logloss:0.519673\n",
      "[50]\teval-logloss:0.644238\ttrain-logloss:0.505495\n",
      "[60]\teval-logloss:0.643028\ttrain-logloss:0.483072\n",
      "[70]\teval-logloss:0.64279\ttrain-logloss:0.463482\n",
      "[80]\teval-logloss:0.64387\ttrain-logloss:0.444722\n",
      "[90]\teval-logloss:0.645035\ttrain-logloss:0.433404\n",
      "[100]\teval-logloss:0.646799\ttrain-logloss:0.42103\n",
      "[110]\teval-logloss:0.648315\ttrain-logloss:0.409799\n",
      "[120]\teval-logloss:0.65037\ttrain-logloss:0.400508\n",
      "[130]\teval-logloss:0.651744\ttrain-logloss:0.389124\n",
      "[140]\teval-logloss:0.653998\ttrain-logloss:0.380241\n",
      "[150]\teval-logloss:0.655873\ttrain-logloss:0.370247\n",
      "[160]\teval-logloss:0.658325\ttrain-logloss:0.36262\n",
      "[170]\teval-logloss:0.660668\ttrain-logloss:0.354537\n",
      "[180]\teval-logloss:0.662141\ttrain-logloss:0.347834\n",
      "[190]\teval-logloss:0.663946\ttrain-logloss:0.340881\n",
      "\tScore 0.665693369627\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 9, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687678\ttrain-logloss:0.681541\n",
      "[10]\teval-logloss:0.663159\ttrain-logloss:0.626614\n",
      "[20]\teval-logloss:0.650574\ttrain-logloss:0.589226\n",
      "[30]\teval-logloss:0.644027\ttrain-logloss:0.564169\n",
      "[40]\teval-logloss:0.640947\ttrain-logloss:0.542582\n",
      "[50]\teval-logloss:0.638108\ttrain-logloss:0.522781\n",
      "[60]\teval-logloss:0.636427\ttrain-logloss:0.506962\n",
      "[70]\teval-logloss:0.636164\ttrain-logloss:0.493793\n",
      "[80]\teval-logloss:0.63623\ttrain-logloss:0.479283\n",
      "[90]\teval-logloss:0.636197\ttrain-logloss:0.466736\n",
      "[100]\teval-logloss:0.637647\ttrain-logloss:0.454999\n",
      "[110]\teval-logloss:0.637489\ttrain-logloss:0.44585\n",
      "[120]\teval-logloss:0.637884\ttrain-logloss:0.437385\n",
      "[130]\teval-logloss:0.6379\ttrain-logloss:0.426372\n",
      "[140]\teval-logloss:0.639092\ttrain-logloss:0.417036\n",
      "[150]\teval-logloss:0.640307\ttrain-logloss:0.407873\n",
      "[160]\teval-logloss:0.642882\ttrain-logloss:0.399802\n",
      "[170]\teval-logloss:0.643988\ttrain-logloss:0.39344\n",
      "[180]\teval-logloss:0.645051\ttrain-logloss:0.388235\n",
      "[190]\teval-logloss:0.647098\ttrain-logloss:0.381713\n",
      "\tScore 0.648086884226\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 10, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687281\ttrain-logloss:0.678226\n",
      "[10]\teval-logloss:0.662086\ttrain-logloss:0.61144\n",
      "[20]\teval-logloss:0.6538\ttrain-logloss:0.576151\n",
      "[30]\teval-logloss:0.6497\ttrain-logloss:0.550356\n",
      "[40]\teval-logloss:0.643803\ttrain-logloss:0.519673\n",
      "[50]\teval-logloss:0.644238\ttrain-logloss:0.505495\n",
      "[60]\teval-logloss:0.643028\ttrain-logloss:0.483072\n",
      "[70]\teval-logloss:0.64279\ttrain-logloss:0.463482\n",
      "[80]\teval-logloss:0.64387\ttrain-logloss:0.444722\n",
      "[90]\teval-logloss:0.645035\ttrain-logloss:0.433404\n",
      "[100]\teval-logloss:0.646799\ttrain-logloss:0.42103\n",
      "[110]\teval-logloss:0.648315\ttrain-logloss:0.409799\n",
      "[120]\teval-logloss:0.65037\ttrain-logloss:0.400508\n",
      "[130]\teval-logloss:0.651744\ttrain-logloss:0.389124\n",
      "[140]\teval-logloss:0.653998\ttrain-logloss:0.380241\n",
      "[150]\teval-logloss:0.655873\ttrain-logloss:0.370247\n",
      "[160]\teval-logloss:0.658325\ttrain-logloss:0.36262\n",
      "[170]\teval-logloss:0.660668\ttrain-logloss:0.354537\n",
      "[180]\teval-logloss:0.662141\ttrain-logloss:0.347834\n",
      "[190]\teval-logloss:0.663946\ttrain-logloss:0.340881\n",
      "\tScore 0.665693369627\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 11, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.686499\ttrain-logloss:0.674053\n",
      "[10]\teval-logloss:0.657764\ttrain-logloss:0.590396\n",
      "[20]\teval-logloss:0.651679\ttrain-logloss:0.561574\n",
      "[30]\teval-logloss:0.646548\ttrain-logloss:0.52885\n",
      "[40]\teval-logloss:0.644355\ttrain-logloss:0.496326\n",
      "[50]\teval-logloss:0.642851\ttrain-logloss:0.470656\n",
      "[60]\teval-logloss:0.645042\ttrain-logloss:0.44988\n",
      "[70]\teval-logloss:0.648513\ttrain-logloss:0.434128\n",
      "[80]\teval-logloss:0.648519\ttrain-logloss:0.419097\n",
      "[90]\teval-logloss:0.650444\ttrain-logloss:0.401523\n",
      "[100]\teval-logloss:0.65252\ttrain-logloss:0.391229\n",
      "[110]\teval-logloss:0.654853\ttrain-logloss:0.378585\n",
      "[120]\teval-logloss:0.657778\ttrain-logloss:0.3664\n",
      "[130]\teval-logloss:0.660271\ttrain-logloss:0.354111\n",
      "[140]\teval-logloss:0.66364\ttrain-logloss:0.345489\n",
      "[150]\teval-logloss:0.666432\ttrain-logloss:0.338045\n",
      "[160]\teval-logloss:0.668853\ttrain-logloss:0.330443\n",
      "[170]\teval-logloss:0.672456\ttrain-logloss:0.323453\n",
      "[180]\teval-logloss:0.676028\ttrain-logloss:0.31509\n",
      "[190]\teval-logloss:0.678446\ttrain-logloss:0.309669\n",
      "\tScore 0.682098786859\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 9, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687678\ttrain-logloss:0.681541\n",
      "[10]\teval-logloss:0.663159\ttrain-logloss:0.626614\n",
      "[20]\teval-logloss:0.650574\ttrain-logloss:0.589226\n",
      "[30]\teval-logloss:0.644027\ttrain-logloss:0.564169\n",
      "[40]\teval-logloss:0.640947\ttrain-logloss:0.542582\n",
      "[50]\teval-logloss:0.638108\ttrain-logloss:0.522781\n",
      "[60]\teval-logloss:0.636427\ttrain-logloss:0.506962\n",
      "[70]\teval-logloss:0.636164\ttrain-logloss:0.493793\n",
      "[80]\teval-logloss:0.63623\ttrain-logloss:0.479283\n",
      "[90]\teval-logloss:0.636197\ttrain-logloss:0.466736\n",
      "[100]\teval-logloss:0.637647\ttrain-logloss:0.454999\n",
      "[110]\teval-logloss:0.637489\ttrain-logloss:0.44585\n",
      "[120]\teval-logloss:0.637884\ttrain-logloss:0.437385\n",
      "[130]\teval-logloss:0.6379\ttrain-logloss:0.426372\n",
      "[140]\teval-logloss:0.639092\ttrain-logloss:0.417036\n",
      "[150]\teval-logloss:0.640307\ttrain-logloss:0.407873\n",
      "[160]\teval-logloss:0.642882\ttrain-logloss:0.399802\n",
      "[170]\teval-logloss:0.643988\ttrain-logloss:0.39344\n",
      "[180]\teval-logloss:0.645051\ttrain-logloss:0.388235\n",
      "[190]\teval-logloss:0.647098\ttrain-logloss:0.381713\n",
      "\tScore 0.648086884226\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 11, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.686499\ttrain-logloss:0.674053\n",
      "[10]\teval-logloss:0.657764\ttrain-logloss:0.590396\n",
      "[20]\teval-logloss:0.651679\ttrain-logloss:0.561574\n",
      "[30]\teval-logloss:0.646548\ttrain-logloss:0.52885\n",
      "[40]\teval-logloss:0.644355\ttrain-logloss:0.496326\n",
      "[50]\teval-logloss:0.642851\ttrain-logloss:0.470656\n",
      "[60]\teval-logloss:0.645042\ttrain-logloss:0.44988\n",
      "[70]\teval-logloss:0.648513\ttrain-logloss:0.434128\n",
      "[80]\teval-logloss:0.648519\ttrain-logloss:0.419097\n",
      "[90]\teval-logloss:0.650444\ttrain-logloss:0.401523\n",
      "[100]\teval-logloss:0.65252\ttrain-logloss:0.391229\n",
      "[110]\teval-logloss:0.654853\ttrain-logloss:0.378585\n",
      "[120]\teval-logloss:0.657778\ttrain-logloss:0.3664\n",
      "[130]\teval-logloss:0.660271\ttrain-logloss:0.354111\n",
      "[140]\teval-logloss:0.66364\ttrain-logloss:0.345489\n",
      "[150]\teval-logloss:0.666432\ttrain-logloss:0.338045\n",
      "[160]\teval-logloss:0.668853\ttrain-logloss:0.330443\n",
      "[170]\teval-logloss:0.672456\ttrain-logloss:0.323453\n",
      "[180]\teval-logloss:0.676028\ttrain-logloss:0.31509\n",
      "[190]\teval-logloss:0.678446\ttrain-logloss:0.309669\n",
      "\tScore 0.682098786859\n",
      "\n",
      "\n",
      "Training with params : \n",
      "{'n_estimators': 200, 'objective': 'binary:logistic', 'max_depth': 9, 'eval_metric': 'logloss', 'silent': 1}\n",
      "[0]\teval-logloss:0.687678\ttrain-logloss:0.681541\n",
      "[10]\teval-logloss:0.663159\ttrain-logloss:0.626614\n",
      "[20]\teval-logloss:0.650574\ttrain-logloss:0.589226\n",
      "[30]\teval-logloss:0.644027\ttrain-logloss:0.564169\n",
      "[40]\teval-logloss:0.640947\ttrain-logloss:0.542582\n",
      "[50]\teval-logloss:0.638108\ttrain-logloss:0.522781\n",
      "[60]\teval-logloss:0.636427\ttrain-logloss:0.506962\n",
      "[70]\teval-logloss:0.636164\ttrain-logloss:0.493793\n",
      "[80]\teval-logloss:0.63623\ttrain-logloss:0.479283\n",
      "[90]\teval-logloss:0.636197\ttrain-logloss:0.466736\n",
      "[100]\teval-logloss:0.637647\ttrain-logloss:0.454999\n",
      "[110]\teval-logloss:0.637489\ttrain-logloss:0.44585\n",
      "[120]\teval-logloss:0.637884\ttrain-logloss:0.437385\n",
      "[130]\teval-logloss:0.6379\ttrain-logloss:0.426372\n",
      "[140]\teval-logloss:0.639092\ttrain-logloss:0.417036\n",
      "[150]\teval-logloss:0.640307\ttrain-logloss:0.407873\n",
      "[160]\teval-logloss:0.642882\ttrain-logloss:0.399802\n",
      "[170]\teval-logloss:0.643988\ttrain-logloss:0.39344\n",
      "[180]\teval-logloss:0.645051\ttrain-logloss:0.388235\n",
      "[190]\teval-logloss:0.647098\ttrain-logloss:0.381713\n",
      "\tScore 0.648086884226\n",
      "\n",
      "\n",
      "{'max_depth': 1}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xdatatrain = xgb.DMatrix(data = xtrain, label = ytrain)\n",
    "Xdatatest = xgb.DMatrix(data = xval, label = yval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space ={\n",
    "        'max_depth': hp.choice('max_depth', np.arange(8, 12, 1, dtype=int)),\n",
    "        'subsample': hp.choice('subsample', np.arange(0.8, 1, 0.1, dtype=int)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x11a1c79d0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space['max_depth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(9,)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот несколько идей, которые помогут воспроизвести новый baseline:\n",
    "\n",
    "1) Чтобы тюнить алгоритмы, нужно иметь \"правильную\" кросс-валидацию. В сореваниях \"правильной\" кросс-валидацией является та, которая имеет ту же структуру, как и разбиение данных на трейн и тест. Если кросс-валидация \"правильная\", то улучшение качества на ней будет соответствовать улучшению качества на лидерборде. Если \"неправильная\", то можно переобучиться - улучшить качество на кросс-валидации, но ухудшить его на лидерборде (то есть на тестовых данных). \n",
    "\n",
    "2) Xgboost - это алгоритм бустинга деревьев. На каждом шаге к уже имеющемуся набору деревьев добавляется новое, таким образом, чтобы уменьшить ошибку всей композиции. Старые деревья не меняются. Таким образом, если на шаге k текущее предсказание бустинга это Yk, а предсказание от нового дерева это pk, то Y{k+1} = Yk + coeff * pk.\n",
    "\n",
    "Основные параметры хгбуста:\n",
    "\n",
    "max_depth - глубина деревьев в бустинге,\n",
    "\n",
    "subsample - каждое дерево обучается на случайной подвыборке данных, пропорциональной значению subsample. Subsample == 1 значит, что каждой дерево получает все строки данных, Subsample == 0.5 — случайно выбранную половину.\n",
    "\n",
    "colsample_bytree - выбор доли признаков, которые будут использованы одним деревом в композиции. Аналогично subsample.\n",
    "\n",
    "eta - коэффициент с которым новое дерево в композиции влияет на уже имеющееся предсказание. eta это максимальное по модулю значение, которое может принимать coeff из формулы выше.\n",
    "\n",
    "https://github.com/dmlc/xgboost/blob/master/doc/param..\n",
    "\n",
    "Инвайт в контест https://kaggle.com/join/dmia_sport0_join\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strange, but it seems like we got 0.658 instead of 0.649! \n",
    "\n",
    "### What could it be? Perhabs we need to train on all data instead of just 40% of it? Or may be should think over our cross-validation process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's overview now what we just did here:\n",
    "1) made cross-validation\n",
    "\n",
    "2) tried linear models, they didn't work, but we figured out how to tackle this problem\n",
    "\n",
    "3) tried random forest and almost beat constant benchmark\n",
    "\n",
    "4) tried xgboost and finally beat constant prediction!\n",
    "\n",
    "### But there is the last thing you must know before you'll start this challenge by trying to make the most thorough parameter tuning: the data has it's secrets and those who will find them will be generously rewarded...\n",
    "\n",
    "### now, good luck with it!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
