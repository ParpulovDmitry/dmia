{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # calculations with arrays\n",
    "import pandas as pd # user-friendly DataFrames for data representation\n",
    "import sklearn # machine learning algorithms\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "import matplotlib.pyplot as plt # import plot functions\n",
    "# necessary to plot in jupyter notebook:\n",
    "%matplotlib inline\n",
    "import seaborn as sns # make plots beautiful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from competition's page\n",
    "\n",
    "https://inclass.kaggle.com/c/data-mining-in-action-2016-competitions-01/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2998</td>\n",
       "      <td>19</td>\n",
       "      <td>317</td>\n",
       "      <td>131</td>\n",
       "      <td>336</td>\n",
       "      <td>278</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  day  team1  team2  score1  score2 target\n",
       "0  2998   19    317    131     336     278   True"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first row\n",
    "train[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2\n",
       "0   0  3021    363    161"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0     0.5"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target variable is \"target\" and this means we will be predicting it\n",
    "sample_submission[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the unique values in data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year [2998 2999 3000 3001 3002]\n",
      "day [19 28 30 31 33]\n",
      "team1 [317  61 110 352 229]\n",
      "team2 [131  29 141 146  91]\n",
      "score1 [336 301 359 309 332]\n",
      "score2 [278 259 267 410 220]\n",
      "target [True False]\n"
     ]
    }
   ],
   "source": [
    "for c in train.columns:\n",
    "    print c, train[c].unique()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets split data randomly to train and validatation. We will train our algorithms on selected train set and validate them on validation set. Easy as it can be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101609, 7)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train size\n",
    "train.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train is quite big, so for example purposes we'll sample only part of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "for itr, ite in ShuffleSplit(len(train), n_iter=1, train_size=0.4, test_size=0.1, random_state=0):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "information about all functions can be found on the internet, for example\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# or you can open it in you Jupyter notebook executing function in this manner\n",
    "?ShuffleSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40643, 10161)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itr), len(ite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([22710, 41665, 91975, 57348, 39931]),\n",
       " array([ 37078, 101474,  29858,  61674,   1049]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itr[:5], ite[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we have validation set \"ite\" to check the quality of our solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  target\n",
       "0   0     0.5\n",
       "1   1     0.5"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to change 'target' column in \"sample_submission\" to our predictions.\n",
    "\n",
    "For now we will select only features that are present in both train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"year\" is present in test and train\n",
      "\"day\" is NOT present in test\n",
      "\"team1\" is present in test and train\n",
      "\"team2\" is present in test and train\n",
      "\"score1\" is NOT present in test\n",
      "\"score2\" is NOT present in test\n",
      "\"target\" is NOT present in test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['year', 'team1', 'team2']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = []\n",
    "for c in train.columns:\n",
    "    if c in test.columns and c!='target':\n",
    "        features += [c]\n",
    "        print '\"{}\" is present in test and train'.format(c)\n",
    "    else:\n",
    "        print '\"{}\" is NOT present in test'.format(c)\n",
    "        \n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here we split train on \"train\" and \"validation\" parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xtrain = train.loc[itr, features]    \n",
    "ytrain = train.loc[itr, 'target']\n",
    "\n",
    "xval = train.loc[ite, features]\n",
    "yval = train.loc[ite, 'target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline solution\n",
    "\n",
    "lets make baseline first by predicting the mean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50096940231672393"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5009694,  0.5009694,  0.5009694, ...,  0.5009694,  0.5009694,\n",
       "        0.5009694])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constant_prediction = yval * 0 + train.target.mean()\n",
    "constant_prediction = constant_prediction.values\n",
    "constant_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931565015839517"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, constant_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission.target = train['target'].mean() # notice here that we can refer to a column 'target' in two ways\n",
    "submission.to_csv('constant_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this should score like \"Baseline - Constant\" on Leaderboard!\n",
    "You can submit this by going to \n",
    "\n",
    "https://inclass.kaggle.com/c/data-mining-in-action-2016-competitions-01/submissions/attach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple prob solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(pd.unique(train[\"team1\"])) == sorted(pd.unique(train[\"team2\"])) # the same commands!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "team_names = sorted(pd.unique(train[\"team1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6967152686762779"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_name = 317\n",
    "prob_t1 = float(train[train[\"team1\"]==team_name].target.sum())/train[train[\"team1\"]==team_name].target.shape[0]\n",
    "prob_t2 = 1 - float(train[train[\"team2\"]==team_name].target.sum())/train[train[\"team2\"]==team_name].target.shape[0]\n",
    "\n",
    "all_prob_to_win = 0.5*(prob_t1 + prob_t2)    ## probability that team wins\n",
    "all_prob_to_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = train.loc[itr]\n",
    "val_set = train.loc[ite]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.68 s, sys: 17.6 ms, total: 1.69 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = {}\n",
    "for team_name in team_names:\n",
    "    prob_t1 = float(train_set[train_set[\"team1\"]==team_name].target.sum())/train_set[train_set[\"team1\"]==team_name].target.shape[0]\n",
    "    prob_t2 = 1 - float(train_set[train_set[\"team2\"]==team_name].target.sum())/train_set[train_set[\"team2\"]==team_name].target.shape[0]\n",
    "\n",
    "    all_prob_to_win = 0.5*(prob_t1 + prob_t2)    ## probability that team wins\n",
    "    d[team_name] = all_prob_to_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175906183368871"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_set[\"prob_t1_win\"] = val_set[\"team1\"].apply(lambda x: d.get(x, 0.5))\n",
    "val_set[\"prob_t2_win\"] = val_set[\"team2\"].apply(lambda x: d.get(x, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_set[\"prob_t2_lost\"] = 1 - val_set[\"prob_t2_win\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>day</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>target</th>\n",
       "      <th>prob_t1_win</th>\n",
       "      <th>prob_t2_win</th>\n",
       "      <th>prob_t2_lost</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37078</th>\n",
       "      <td>3006</td>\n",
       "      <td>214</td>\n",
       "      <td>305</td>\n",
       "      <td>196</td>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>True</td>\n",
       "      <td>0.457215</td>\n",
       "      <td>0.360509</td>\n",
       "      <td>0.639491</td>\n",
       "      <td>0.554983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101474</th>\n",
       "      <td>3019</td>\n",
       "      <td>226</td>\n",
       "      <td>361</td>\n",
       "      <td>207</td>\n",
       "      <td>178</td>\n",
       "      <td>228</td>\n",
       "      <td>False</td>\n",
       "      <td>0.539470</td>\n",
       "      <td>0.670008</td>\n",
       "      <td>0.329992</td>\n",
       "      <td>0.418075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29858</th>\n",
       "      <td>3005</td>\n",
       "      <td>95</td>\n",
       "      <td>178</td>\n",
       "      <td>204</td>\n",
       "      <td>212</td>\n",
       "      <td>197</td>\n",
       "      <td>True</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.592766</td>\n",
       "      <td>0.407234</td>\n",
       "      <td>0.519045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61674</th>\n",
       "      <td>3012</td>\n",
       "      <td>90</td>\n",
       "      <td>290</td>\n",
       "      <td>243</td>\n",
       "      <td>224</td>\n",
       "      <td>131</td>\n",
       "      <td>True</td>\n",
       "      <td>0.670447</td>\n",
       "      <td>0.628573</td>\n",
       "      <td>0.371427</td>\n",
       "      <td>0.518998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>2998</td>\n",
       "      <td>93</td>\n",
       "      <td>354</td>\n",
       "      <td>186</td>\n",
       "      <td>270</td>\n",
       "      <td>259</td>\n",
       "      <td>True</td>\n",
       "      <td>0.538218</td>\n",
       "      <td>0.480051</td>\n",
       "      <td>0.519949</td>\n",
       "      <td>0.510154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  day  team1  team2  score1  score2 target  prob_t1_win  \\\n",
       "37078   3006  214    305    196     263     247   True     0.457215   \n",
       "101474  3019  226    361    207     178     228  False     0.539470   \n",
       "29858   3005   95    178    204     212     197   True     0.560000   \n",
       "61674   3012   90    290    243     224     131   True     0.670447   \n",
       "1049    2998   93    354    186     270     259   True     0.538218   \n",
       "\n",
       "        prob_t2_win  prob_t2_lost      pred  \n",
       "37078      0.360509      0.639491  0.554983  \n",
       "101474     0.670008      0.329992  0.418075  \n",
       "29858      0.592766      0.407234  0.519045  \n",
       "61674      0.628573      0.371427  0.518998  \n",
       "1049       0.480051      0.519949  0.510154  "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_set[\"pred\"] = (val_set[\"prob_t1_win\"] + val_set[\"prob_t2_lost\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65446123409511436"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(list(val_set[\"target\"]), list(val_set[\"pred\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_subm = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_subm[\"prob_t1_win\"] = for_subm[\"team1\"].apply(lambda x: d.get(x, 0.5))\n",
    "for_subm[\"prob_t2_win\"] = for_subm[\"team2\"].apply(lambda x: d.get(x, 0.5))\n",
    "for_subm[\"prob_t2_lost\"] = 1 - for_subm[\"prob_t2_win\"]\n",
    "for_subm[\"target\"] = (for_subm[\"prob_t1_win\"] + for_subm[\"prob_t2_lost\"])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>year</th>\n",
       "      <th>team1</th>\n",
       "      <th>team2</th>\n",
       "      <th>prob_t1_win</th>\n",
       "      <th>prob_t2_win</th>\n",
       "      <th>prob_t2_lost</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3021</td>\n",
       "      <td>363</td>\n",
       "      <td>161</td>\n",
       "      <td>0.437586</td>\n",
       "      <td>0.490602</td>\n",
       "      <td>0.509398</td>\n",
       "      <td>0.473492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3021</td>\n",
       "      <td>286</td>\n",
       "      <td>2</td>\n",
       "      <td>0.590380</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.613043</td>\n",
       "      <td>0.601712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3020</td>\n",
       "      <td>232</td>\n",
       "      <td>52</td>\n",
       "      <td>0.546654</td>\n",
       "      <td>0.218915</td>\n",
       "      <td>0.781085</td>\n",
       "      <td>0.663869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3020</td>\n",
       "      <td>84</td>\n",
       "      <td>11</td>\n",
       "      <td>0.404520</td>\n",
       "      <td>0.478844</td>\n",
       "      <td>0.521156</td>\n",
       "      <td>0.462838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3021</td>\n",
       "      <td>305</td>\n",
       "      <td>39</td>\n",
       "      <td>0.457215</td>\n",
       "      <td>0.689543</td>\n",
       "      <td>0.310457</td>\n",
       "      <td>0.383836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  year  team1  team2  prob_t1_win  prob_t2_win  prob_t2_lost    target\n",
       "0   0  3021    363    161     0.437586     0.490602      0.509398  0.473492\n",
       "1   1  3021    286      2     0.590380     0.386957      0.613043  0.601712\n",
       "2   2  3020    232     52     0.546654     0.218915      0.781085  0.663869\n",
       "3   3  3020     84     11     0.404520     0.478844      0.521156  0.462838\n",
       "4   4  3021    305     39     0.457215     0.689543      0.310457  0.383836"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for_subm.drop([\"prob_t1_win\", \"prob_t2_win\", \"prob_t2_lost\", \"year\", \"team1\", \"team2\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.473492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.601712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.663869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.462838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.383836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    target\n",
       "0   0  0.473492\n",
       "1   1  0.601712\n",
       "2   2  0.663869\n",
       "3   3  0.462838\n",
       "4   4  0.383836"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for_subm.to_csv(\"prob_solution.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning\n",
    "\n",
    "Finally, lets try machine learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = linear_model.LogisticRegression()\n",
    "alg.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69278091662349195"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well, not so far from the constant solution... Let's try to understand why.\n",
    "\n",
    "What's a linear model such as LogisticRegression is trying to do is multiply each variable on some coefficient and add add it up, in our case:\n",
    "\n",
    "y_predicted = column1 \\* coef1 + column2 \\* coef2 + column3 \\* coef3 + bias\n",
    "\n",
    "We can print coefficients and bias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2.31737378e-07,   3.29139376e-04,  -2.98254396e-04]]),\n",
       " array([  5.62890115e-09]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg.coef_, alg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But clearly, \"team1\" and \"team2\" are _categorical_ columns, just like names of the teams. \n",
    "\n",
    "So we need to turn \"team\" columns to something linear algorithm can work with. For example first few rows from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    317\n",
       "1     61\n",
       "2    110\n",
       "Name: team1, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[:2, 'team1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>61</th>\n",
       "      <th>110</th>\n",
       "      <th>317</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   61   110  317\n",
       "0  0.0  0.0  1.0\n",
       "1  1.0  0.0  0.0\n",
       "2  0.0  1.0  0.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(train.loc[:2, 'team1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each team name now has it's own column. Read about \"pd.get_dummies\" here:\n",
    "\n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But let's come back to more interesting stuff for now\n",
    "### We are competition's solvers, remember? Lets dive into the space of more complicated models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = ensemble.RandomForestClassifier(15, n_jobs=4)\n",
    "alg.fit(xtrain, ytrain)\n",
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1744940647416549"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, this doesn't work very well. Now, like competition pro, let's make our models bigger!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alg = ensemble.RandomForestClassifier(150, n_jobs=4)\n",
    "alg.fit(xtrain, ytrain)\n",
    "prediction = alg.predict_proba(xval)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74131637899967551"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost there! But for now let's skip this model too and go to _real_ competitions stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['max_depth'] = 8\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['eta'] = 0.1\n",
    "\n",
    "numround = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost parameters\n",
    "\n",
    "https://github.com/dmlc/xgboost/blob/master/doc/parameter.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.689826\teval-logloss:0.691345\n",
      "[10]\ttrain-logloss:0.670759\teval-logloss:0.681402\n",
      "[20]\ttrain-logloss:0.658005\teval-logloss:0.67538\n",
      "[30]\ttrain-logloss:0.647507\teval-logloss:0.669858\n",
      "[40]\ttrain-logloss:0.638459\teval-logloss:0.66616\n",
      "[50]\ttrain-logloss:0.628218\teval-logloss:0.661736\n",
      "[60]\ttrain-logloss:0.619701\teval-logloss:0.658285\n",
      "[70]\ttrain-logloss:0.6126\teval-logloss:0.655751\n",
      "[80]\ttrain-logloss:0.604423\teval-logloss:0.652431\n",
      "[90]\ttrain-logloss:0.597331\teval-logloss:0.649311\n"
     ]
    }
   ],
   "source": [
    "Xdatatrain = xgboost.DMatrix(data = xtrain, label = ytrain)\n",
    "Xdatatest = xgboost.DMatrix(data = xval, label = yval)\n",
    "\n",
    "plst = list(param.items())\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist, verbose_eval = 10)\n",
    "# ypredxgb_tr = bst.predict(Xdatatrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! Finally our model better than constant predictions! Congratulations! Don't hesitate, submit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = sample_submission.copy()\n",
    "\n",
    "ss.target = bst.predict(xgboost.DMatrix(test[features]))\n",
    "ss.to_csv('mighty_xgboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strange, but it seems like we got 0.658 instead of 0.649! \n",
    "\n",
    "### What could it be? Perhabs we need to train on all data instead of just 40% of it? Or may be should think over our cross-validation process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's overview now what we just did here:\n",
    "1) made cross-validation\n",
    "\n",
    "2) tried linear models, they didn't work, but we figured out how to tackle this problem\n",
    "\n",
    "3) tried random forest and almost beat constant benchmark\n",
    "\n",
    "4) tried xgboost and finally beat constant prediction!\n",
    "\n",
    "### But there is the last thing you must know before you'll start this challenge by trying to make the most thorough parameter tuning: the data has it's secrets and those who will find them will be generously rewarded...\n",
    "\n",
    "### now, good luck with it!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
